{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3fb515a",
   "metadata": {},
   "source": [
    "# Paper-ready Figures: Franka and Robot Navigation Experiments\n",
    "\n",
    "This notebook loads the saved analysis outputs (experiment_analysis.json and experiment_raw_data.pkl) produced by the Franka and Robot Navigation experiments and generates compact, publication-quality figures.\n",
    "\n",
    "- Titles use human-readable academic naming (no underscores).\n",
    "- Preset color theme and tight figure layouts suitable for papers.\n",
    "- Figures are saved back into each experiment output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c2d1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and plotting theme\n",
    "import os, json, pickle, glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['DejaVu Sans', 'Helvetica', 'Arial'],\n",
    "    'font.size': 10,\n",
    "    'axes.titlesize': 11,\n",
    "    'axes.labelsize': 10,\n",
    "    'xtick.labelsize': 9,\n",
    "    'ytick.labelsize': 9,\n",
    "    'legend.fontsize': 9,\n",
    "    'figure.dpi': 300,\n",
    "    'axes.linewidth': 0.8\n",
    "})\n",
    "\n",
    "# Compact palette for paper figures\n",
    "# PAPER_PALETTE = ['#CFD8DC', \"#A9D7F7\", \"#49A8E7\", \"#4a89cc\"]\n",
    "PAPER_PALETTE = [\"#D7E3E7\", \"#A9D7F7\", \"#49A8E7\", \"#4a89cc\"]  # blue, gold, green, coral\n",
    "PAPER_PALETTE2 = [\"#FFF9A6\", \"#FFD87D\", \"#FFA726\", \"#FF4800\"]  # blue, gold, green, coral\n",
    "\n",
    "AI_PALETTE_EXTENDED = {\n",
    "    # 核心色系\n",
    "    'main': '#607D8B',        # 主色调（科技灰蓝）\n",
    "\n",
    "    # 辅助色分级（新增2级）\n",
    "    'aux1': '#CFD8DC',        # 浅灰蓝（次级数据）\n",
    "    'aux2': '#71b7c8',        # 更浅灰蓝（背景元素）\n",
    "    'aux5': '#3a6fa6',        # 中灰蓝（网格/注释）\n",
    "    'aux4': '#455A64',        # 深灰蓝（强调文本）\n",
    "    'aux3': '#FFA726',        # 活力橙（警示/交互）\n",
    "\n",
    "    # 中性色体系\n",
    "    'neutral1': '#ECEFF1',    # 浅灰背景（适配深色模式）\n",
    "    'neutral2': '#263238',    # 深灰文字（高对比度）\n",
    "    'neutral3': '#B0BEC5'     # 中灰网格（原aux2复用）\n",
    "}\n",
    "\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_palette(PAPER_PALETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2415f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: load analysis JSON and raw pickle (if present)\n",
    "def load_analysis(output_dir):\n",
    "    analysis_path = Path(output_dir) / 'experiment_analysis.json'\n",
    "    raw_path = Path(output_dir) / 'experiment_raw_data.pkl'\n",
    "    analysis = None\n",
    "    raw = None\n",
    "    if analysis_path.exists():\n",
    "        with open(analysis_path, 'r', encoding='utf-8') as f:\n",
    "            analysis = json.load(f)\n",
    "    if raw_path.exists():\n",
    "        try:\n",
    "            with open(raw_path, 'rb') as f:\n",
    "                raw = pickle.load(f)\n",
    "        except Exception:\n",
    "            raw = None\n",
    "    return analysis, raw\n",
    "\n",
    "def nice_name(method_key):\n",
    "    method_key_remap = {\n",
    "        \"AVWBFO_MC_Linear\": \"AV-WBFO + MC\",\n",
    "        \"AVWBFO_LHS_Linear\": \"AV-WBFO + LHS\",\n",
    "        \"MPPI_MC_Linear\": \"MPPI + MC\",\n",
    "        \"MPPI_LHS_Linear\": \"MPPI + LHS\",\n",
    "        \"elair_barrier_nav_VanillaRL\": \"Vanilla RL\",\n",
    "        \"elair_barrier_nav_AVWBFO_RL\": \"AV-WBFO w RL\",\n",
    "        \"elair_barrier_nav_AVWBFO\": \"AV-WBFO w/o RL\",\n",
    "        \"elair_barrier_nav_MPPI_RL\": \"MPPI w RL\",\n",
    "        \"elair_barrier_nav_MPPI\": \"MPPI w/o RL\",\n",
    "    }\n",
    "    # Replace underscores, common abbreviations to nicer titles\n",
    "    return method_key_remap.get(method_key, method_key.replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcccc799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot helpers: compact bar with error, compact table and reward curves\n",
    "def bar_with_error(ax, labels, means, stds, colors=None, ylabel='', title=''):\n",
    "    x = np.arange(len(labels))\n",
    "    if colors is None:\n",
    "        colors = PAPER_PALETTE[:len(labels)]\n",
    "    bars = ax.bar(x, means, yerr=stds, color=colors, capsize=4, linewidth=0.6, edgecolor='black', alpha=0.95)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=0, ha='center')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title, pad=6)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis='y', alpha=0.25)\n",
    "    # Add compact labels\n",
    "    for b, m, s in zip(bars, means, stds):\n",
    "        h = b.get_height()\n",
    "        ax.text(b.get_x() + b.get_width()/4*3 if s>0 else b.get_x() + b.get_width()/2, \n",
    "                h + max(0.01, 0.02 * max(1.0, h)), \n",
    "                f'{m:.2f}\\n±{s:.2f}' if s > 0 else f'{m:.2f}',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "def compact_summary_table(save_path, headers, rows, title=''):\n",
    "    fig, ax = plt.subplots(figsize=(6, max(1.2, 0.25 * len(rows) + 0.8)))\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=rows, colLabels=headers, cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 1.2)\n",
    "    if title:\n",
    "        ax.set_title(title, pad=8, fontsize=11)\n",
    "    fig.tight_layout(pad=0.5)\n",
    "    fig.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "def reward_curves(save_path, reward_histories_by_method, labels, colors, title=''):\n",
    "    fig, ax = plt.subplots(figsize=(6,3.2))\n",
    "    for method in labels:\n",
    "        histories = reward_histories_by_method.get(method, [])\n",
    "        if not histories:\n",
    "            continue\n",
    "        # pad sequences to equal length\n",
    "        max_len = max(len(h) for h in histories)\n",
    "        padded = np.array([np.pad(h, (0, max_len - len(h)), mode='edge') for h in histories])\n",
    "        mean = padded.mean(axis=0)\n",
    "        std = padded.std(axis=0)\n",
    "        idx = np.arange(len(mean))\n",
    "        color = colors[labels.index(method) % len(colors)]\n",
    "        ax.plot(idx, mean, color=color, lw=1.5, label=nice_name(method))\n",
    "        ax.fill_between(idx, mean - std, mean + std, color=color, alpha=0.18)\n",
    "    ax.set_xlabel('Step')\n",
    "    ax.set_ylabel('Mean Step Reward')\n",
    "    ax.set_title(title)\n",
    "    ax.grid(alpha=0.2)\n",
    "    ax.legend(frameon=False, ncol=2, fontsize=8)\n",
    "    fig.tight_layout(pad=0.6)\n",
    "    fig.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "765e89b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franka dir: /home/user/CodeSpace/Python/PredictiveDiffusionPlanner_Dev/doc/records/20250827 Exp1NumSample_Cost/franka_noise_experiment_reach_backward_20250830\n",
      "Robot nav dir: E:/CodeTestFile/Github-private-repo/master_prj/PredictiveDiffusionPlanner_Dev/doc/records/20250902 Exp2ElAirBarrierNav/new_rew2\n"
     ]
    }
   ],
   "source": [
    "# Discover experiment folders (pick latest if multiple) and plot for each\n",
    "def find_latest_dir(pattern):\n",
    "    candidates = glob.glob(pattern)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    # choose newest modified\n",
    "    candidates = sorted(candidates, key=lambda p: os.path.getmtime(p), reverse=True)\n",
    "    return candidates[0]\n",
    "\n",
    "franka_dir = find_latest_dir('./franka_noise_experiment_*')\n",
    "robot_dir = find_latest_dir('./robot_nav_experiment_*')\n",
    "\n",
    "franka_dir = \"/home/user/CodeSpace/Python/PredictiveDiffusionPlanner_Dev/doc/records/20250827 Exp1NumSample_Cost/franka_noise_experiment_reach_backward_20250830\"\n",
    "robot_dir = \"E:/CodeTestFile/Github-private-repo/master_prj/PredictiveDiffusionPlanner_Dev/doc/records/20250902 Exp2ElAirBarrierNav/new_rew2\"\n",
    "\n",
    "print('Franka dir:', franka_dir)\n",
    "print('Robot nav dir:', robot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa0fc3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No analysis JSON in /home/user/CodeSpace/Python/PredictiveDiffusionPlanner_Dev/doc/records/20250827 Exp1NumSample_Cost/franka_noise_experiment_reach_backward_20250830\n"
     ]
    }
   ],
   "source": [
    "# Generate publication-ready figures for Franka experiment (if found)\n",
    "if franka_dir:\n",
    "    analysis, raw = load_analysis(franka_dir)\n",
    "    if analysis is None:\n",
    "        print('No analysis JSON in', franka_dir)\n",
    "    else:\n",
    "        methods = list(analysis.keys())\n",
    "        # Completion rate bar\n",
    "        labels = [nice_name(m) for m in methods]\n",
    "        means = [analysis[m]['summary']['completion_rates']['mean'] for m in methods]\n",
    "        stds = [analysis[m]['summary']['completion_rates']['std'] for m in methods]\n",
    "        fig_path = os.path.join(franka_dir, 'paper_completion_rate.svg')\n",
    "        fig, ax = plt.subplots(figsize=(5.4,2.4))\n",
    "        bar_with_error(ax, labels, means, stds, colors=PAPER_PALETTE, ylabel='Completion Rate', title='Task Completion Rate')\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        # ax.plot([0, len(labels)-1], [1.0, 1.0], 'k--', lw=0.8, alpha=0.6)  # ideal line\n",
    "        ax.grid(axis='y', alpha=0.7)\n",
    "        fig.tight_layout(pad=0.2)\n",
    "        fig.savefig(fig_path, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Mean steps bar\n",
    "        means_s = [analysis[m]['summary']['completion_steps']['mean'] for m in methods]\n",
    "        stds_s = [analysis[m]['summary']['completion_steps']['std'] for m in methods]\n",
    "        fig_path2 = os.path.join(franka_dir, 'paper_mean_steps.svg')\n",
    "        fig, ax = plt.subplots(figsize=(5.4,2.4))\n",
    "        bar_with_error(ax, labels, means_s, stds_s, colors=PAPER_PALETTE, ylabel='Mean Steps', title='Mean Steps to Completion')\n",
    "        ax.set_xticklabels(labels, rotation=0, ha='center')\n",
    "        fig.tight_layout(pad=0.2)\n",
    "        fig.savefig(fig_path2, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Reward curves\n",
    "        reward_histories = {}\n",
    "        for m in methods:\n",
    "            rh = analysis[m].get('raw_data', {}).get('reward_histories', [])\n",
    "            reward_histories[m] = rh\n",
    "        reward_path = os.path.join(franka_dir, 'paper_reward_profiles.svg')\n",
    "        reward_curves(reward_path, reward_histories, methods, PAPER_PALETTE, title='Reward Profile by Method')\n",
    "\n",
    "        # Summary table\n",
    "        headers = ['Method', 'Completion Rate', 'Mean Steps', 'Avg Reward', 'Opt Time (s)']\n",
    "        rows = []\n",
    "        for m in methods:\n",
    "            s = analysis[m]['summary']\n",
    "            rows.append([nice_name(m),\n",
    "                         f\"{s['completion_rates']['mean']:.3f} ± {s['completion_rates']['std']:.3f}\",\n",
    "                         f\"{s['completion_steps']['mean']:.1f} ± {s['completion_steps']['std']:.1f}\",\n",
    "                         f\"{s['average_rewards']['mean']:.3f} ± {s['average_rewards']['std']:.3f}\",\n",
    "                         f\"{s['optimization_times']['mean']:.3f} ± {s['optimization_times']['std']:.3f}\"])\n",
    "        table_path = os.path.join(franka_dir, 'paper_summary_table.svg')\n",
    "        compact_summary_table(table_path, headers, rows, title='Experimental Summary')\n",
    "\n",
    "        print('Saved Franka paper figures to', franka_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddbb4f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: 0\n",
      "cp: 20\n",
      "cp: 15\n",
      "cp: 20\n",
      "cp: 10\n",
      "dict_keys(['summary'])\n",
      "Saved Robot Navigation paper figures to E:/CodeTestFile/Github-private-repo/master_prj/PredictiveDiffusionPlanner_Dev/doc/records/20250902 Exp2ElAirBarrierNav/new_rew2\n",
      "Generated double bar chart: paper_completion_steps_comparison.svg\n",
      "dict_keys(['summary'])\n",
      "Saved Robot Navigation paper figures to E:/CodeTestFile/Github-private-repo/master_prj/PredictiveDiffusionPlanner_Dev/doc/records/20250902 Exp2ElAirBarrierNav/new_rew2\n",
      "Generated double bar chart: paper_completion_steps_comparison.svg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\22059\\AppData\\Local\\Temp\\ipykernel_49240\\3449140773.py:53: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend(frameon=False, ncol=2, fontsize=8)\n"
     ]
    }
   ],
   "source": [
    "# Generate publication-ready figures for Robot Navigation experiment (if found)\n",
    "if robot_dir:\n",
    "    NavSuccPlaette1 = [\"#49A8E7\", \"#005cbe\"]  # blue, gold, green, coral\n",
    "    NavSuccPlaette2 = [ \"#FFA726\", \"#D27E00\"]  # blue, gold, green, coral\n",
    "\n",
    "    \n",
    "    analysis, raw = load_analysis(robot_dir)\n",
    "    if analysis is None:\n",
    "        print('No analysis JSON in', robot_dir)\n",
    "    else:\n",
    "        methods = list(analysis.keys())\n",
    "        labels = [nice_name(m) for m in methods]\n",
    "        \n",
    "        # Navigation success rate with dual y-axis for mean reward\n",
    "        means = [analysis[m]['summary']['navigation_success_rate']['mean'] for m in methods]\n",
    "        stds = [analysis[m]['summary']['navigation_success_rate']['std'] for m in methods]\n",
    "        reward_means = [analysis[m]['summary']['average_rewards']['mean'] for m in methods]\n",
    "        reward_stds = [analysis[m]['summary']['average_rewards']['std'] for m in methods]\n",
    "        \n",
    "        fig_path = os.path.join(robot_dir, 'paper_navigation_success.svg')\n",
    "        fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "        \n",
    "        # Primary y-axis: Navigation Success Rate\n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        bars1 = ax1.bar(x - width/2, means, width, color=NavSuccPlaette1[0], \n",
    "                        linewidth=0.6, edgecolor='black', alpha=0.8,\n",
    "                        label='Navigation Success Rate')\n",
    "        ax1.set_xlabel('Trajectory Optimization Method')\n",
    "        ax1.set_ylabel('Navigation Success Rate', color=NavSuccPlaette1[1])\n",
    "        ax1.set_title('Navigation Success Rate and Mean Reward by Method')\n",
    "        ax1.tick_params(axis='y', labelcolor=NavSuccPlaette1[1])\n",
    "        ax1.set_ylim(0, 1.2)\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(labels, rotation=0, ha='center')\n",
    "        ax1.grid(axis='y', alpha=0.25)\n",
    "        \n",
    "        # Secondary y-axis: Mean Reward\n",
    "        ax2 = ax1.twinx()\n",
    "        bars2 = ax2.bar(x + width/2, reward_means, width, color=NavSuccPlaette2[0],\n",
    "                        linewidth=0.6, edgecolor='black', alpha=0.7,\n",
    "                        label='Mean Reward')\n",
    "        ax2.set_ylabel('Mean Reward', color=NavSuccPlaette2[1])\n",
    "        ax2.tick_params(axis='y', labelcolor=NavSuccPlaette2[1])\n",
    "        \n",
    "        # Add value labels on bars (without error bars)\n",
    "        for bar, mean in zip(bars1, means):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{mean:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        for bar, mean in zip(bars2, reward_means):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{mean:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        # Combine legends\n",
    "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left', frameon=False, fontsize=9)\n",
    "        \n",
    "        fig.tight_layout(pad=0.6)\n",
    "        fig.savefig(fig_path, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Completion steps - Double bar chart (Completed vs All Environments)\n",
    "        completed_only_steps = []\n",
    "        completed_only_stds = []\n",
    "        all_envs_steps = []\n",
    "        all_envs_stds = []\n",
    "        \n",
    "        for method in methods:\n",
    "            # Get max_steps from the first result (assuming all have same max_steps)\n",
    "            max_steps = None\n",
    "            if raw and method in raw:\n",
    "                for result in raw[method]:\n",
    "                    if 'max_steps_allowed' in result:\n",
    "                        max_steps = result['max_steps_allowed']\n",
    "                        break\n",
    "            if max_steps is None:\n",
    "                max_steps = 300  # fallback default\n",
    "            \n",
    "            # Collect all individual completion steps and calculate for both scenarios\n",
    "            method_completed_steps = []\n",
    "            method_all_steps = []\n",
    "            \n",
    "            if raw and method in raw:\n",
    "                for result in raw[method]:\n",
    "                    # Extract individual completion steps from per_env_completion_steps if available\n",
    "                    if 'per_env_completion_steps' in result:\n",
    "                        completion_steps_data = [step for _, step in result['per_env_completion_steps']]\n",
    "                        method_completed_steps.extend(completion_steps_data)\n",
    "                        \n",
    "                        # For all environments calculation, need to know total envs and successful ones\n",
    "                        num_main_envs = result.get('num_main_envs', 20)  # fallback\n",
    "                        num_completed = len(completion_steps_data)\n",
    "                        num_not_completed = num_main_envs - num_completed\n",
    "                        print(\"cp:\", num_completed)\n",
    "                        \n",
    "                        # Add completed steps\n",
    "                        method_all_steps.extend(completion_steps_data)\n",
    "                        # Add max_steps for non-completed environments\n",
    "                        method_all_steps.extend([max_steps] * num_not_completed)\n",
    "                    \n",
    "                    # Fallback: if only mean is available\n",
    "                    elif 'mean_completion_steps' in result and result.get('navigation_success_rate', 0) > 0:\n",
    "                        method_completed_steps.append(result['mean_completion_steps'])\n",
    "                        \n",
    "                        # Estimate all environments based on success rate\n",
    "                        success_rate = result.get('navigation_success_rate', 0)\n",
    "                        num_main_envs = result.get('num_main_envs', 20)\n",
    "                        num_completed = int(success_rate * num_main_envs)\n",
    "                        num_not_completed = num_main_envs - num_completed\n",
    "                        \n",
    "                        method_all_steps.extend([result['mean_completion_steps']] * num_completed)\n",
    "                        method_all_steps.extend([max_steps] * num_not_completed)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            if method_completed_steps:\n",
    "                completed_only_steps.append(float(np.mean(method_completed_steps)))\n",
    "                completed_only_stds.append(float(np.std(method_completed_steps)) if len(method_completed_steps) > 1 else 0.0)\n",
    "            else:\n",
    "                completed_only_steps.append(0.0)\n",
    "                completed_only_stds.append(0.0)\n",
    "            \n",
    "            if method_all_steps:\n",
    "                all_envs_steps.append(float(np.mean(method_all_steps)))\n",
    "                all_envs_stds.append(float(np.std(method_all_steps)) if len(method_all_steps) > 1 else 0.0)\n",
    "            else:\n",
    "                all_envs_steps.append(max_steps)\n",
    "                all_envs_stds.append(0.0)\n",
    "\n",
    "        # Create double bar chart\n",
    "        fig_path2 = os.path.join(robot_dir, 'paper_completion_steps_comparison.svg')\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.44  # width of bars\n",
    "        \n",
    "        # Create bars\n",
    "        bars1 = ax.bar(x - width/2, completed_only_steps, width, yerr=completed_only_stds,\n",
    "                       color=PAPER_PALETTE[2], capsize=4, alpha=0.8, \n",
    "                       label='Completed Environments Only', edgecolor='black', linewidth=0.6)\n",
    "        \n",
    "        bars2 = ax.bar(x + width/2, all_envs_steps, width, yerr=all_envs_stds,\n",
    "                       color=PAPER_PALETTE2[2], capsize=4, alpha=0.8, \n",
    "                       label='All Environments (Failed = Max Steps)', edgecolor='black', linewidth=0.6)\n",
    "\n",
    "        ax.set_ylabel('Mean Steps to Completion')\n",
    "        ax.set_title('Task Completion Efficiency by Method')\n",
    "        ax.set_xlabel('Trajectory Optimization Method')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels, rotation=0, ha='center')\n",
    "        ax.set_ylim(0, max(max(completed_only_steps + all_envs_steps) * 1.3, 50))\n",
    "        ax.legend(frameon=False, fontsize=9, loc='upper right')\n",
    "        ax.grid(axis='y', alpha=0.25)\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for i, (bar1, bar2, steps1, std1, steps2, std2) in enumerate(zip(\n",
    "            bars1, bars2, completed_only_steps, completed_only_stds, all_envs_steps, all_envs_stds)):\n",
    "            \n",
    "            # Labels for completed only bars\n",
    "            height1 = bar1.get_height()\n",
    "            if height1 > 0:  # Only show label if there were completions\n",
    "                ax.text(bar1.get_x() + bar1.get_width()/2., height1 + std1 + 5,\n",
    "                        f'{steps1:.1f}±{std1:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "            \n",
    "            # Labels for all environments bars\n",
    "            height2 = bar2.get_height()\n",
    "            ax.text(bar2.get_x() + bar2.get_width()/2., height2 + std2 + 5,\n",
    "                    f'{steps2:.1f}±{std2:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "        fig.tight_layout(pad=0.6)\n",
    "        fig.savefig(fig_path2, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Compact summary table\n",
    "        headers = ['Method', 'Success Rate', 'Mean Steps', 'Avg Reward', 'Opt Time (s)']\n",
    "        rows = []\n",
    "        for m in methods:\n",
    "            s = analysis[m]['summary']\n",
    "            rows.append([nice_name(m),\n",
    "                         f\"{s['navigation_success_rate']['mean']:.3f} ± {s['navigation_success_rate']['std']:.3f}\",\n",
    "                         f\"{s['completion_steps']['mean']:.1f} ± {s['completion_steps']['std']:.1f}\",\n",
    "                         f\"{s['average_rewards']['mean']:.3f} ± {s['average_rewards']['std']:.3f}\",\n",
    "                         f\"{s['optimization_times']['mean']:.3f} ± {s['optimization_times']['std']:.3f}\"])\n",
    "        table_path = os.path.join(robot_dir, 'paper_summary_table.svg')\n",
    "        compact_summary_table(table_path, headers, rows, title='Experimental Summary')\n",
    "\n",
    "        # If raw reward histories available, plot reward profiles\n",
    "        reward_histories = {}\n",
    "        print(analysis[m].keys())\n",
    "        for m in methods:\n",
    "            rh = analysis[m].get('raw_data', {}).get('reward_histories', [])\n",
    "            reward_histories[m] = rh\n",
    "        reward_path = os.path.join(robot_dir, 'paper_reward_profiles.svg')\n",
    "        reward_curves(reward_path, reward_histories, methods, PAPER_PALETTE, title='Reward Profile by Method')\n",
    "\n",
    "        print('Saved Robot Navigation paper figures to', robot_dir)\n",
    "        print('Generated double bar chart: paper_completion_steps_comparison.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e78355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Completion Steps by Environment and Method ===\n",
      "\n",
      "Method: Vanilla RL\n",
      "--------------------------------------------------\n",
      "  Run 1:\n",
      "    Completed environments (0/20):\n",
      "[]\n",
      "    Failed environments (20/20): [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "    (Failed environments assigned 300 steps)\n",
      "\n",
      "\n",
      "Method: AV-WBFO w RL\n",
      "--------------------------------------------------\n",
      "  Run 1:\n",
      "    Completed environments (20/20):\n",
      "[98, 106, 118, 121, 126, 133, 135, 141, 145, 146, 151, 168, 185, 186, 191, 207, 207, 211, 245, 281]\n",
      "\n",
      "\n",
      "Method: AV-WBFO w/o RL\n",
      "--------------------------------------------------\n",
      "  Run 1:\n",
      "    Completed environments (15/20):\n",
      "[117, 126, 185, 204, 210, 216, 221, 222, 245, 257, 258, 260, 280, 291, 299]\n",
      "    Failed environments (5/20): [1, 5, 11, 13, 17]\n",
      "    (Failed environments assigned 300 steps)\n",
      "\n",
      "\n",
      "Method: MPPI w RL\n",
      "--------------------------------------------------\n",
      "  Run 1:\n",
      "    Completed environments (20/20):\n",
      "[135, 151, 163, 166, 177, 178, 179, 184, 186, 192, 201, 211, 221, 221, 226, 229, 234, 249, 271, 273]\n",
      "\n",
      "\n",
      "Method: MPPI w/o RL\n",
      "--------------------------------------------------\n",
      "  Run 1:\n",
      "    Completed environments (10/20):\n",
      "[160, 173, 193, 201, 251, 270, 271, 271, 290, 297]\n",
      "    Failed environments (10/20): [1, 2, 3, 9, 11, 12, 13, 14, 16, 17]\n",
      "    (Failed environments assigned 300 steps)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if robot_dir:\n",
    "    analysis, raw = load_analysis(robot_dir)\n",
    "    print(\"=== Completion Steps by Environment and Method ===\\n\")\n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"Method: {nice_name(method)}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if method in raw:\n",
    "            for run_idx, result in enumerate(raw[method]):\n",
    "                print(f\"  Run {run_idx + 1}:\")\n",
    "                \n",
    "                if 'per_env_completion_steps' in result:\n",
    "                    env_steps = result['per_env_completion_steps']\n",
    "                    print(f\"    Completed environments ({len(env_steps)}/20):\")\n",
    "                    # for env_idx, steps in env_steps:\n",
    "                    #     print(f\"      Env {env_idx}: {steps} steps\")\n",
    "                    cp_step =[]\n",
    "                    for env_idx, steps in env_steps:\n",
    "                        cp_step.append(steps)\n",
    "                    print(cp_step)\n",
    "                    # Show which environments failed (if any)\n",
    "                    completed_envs = {env_idx for env_idx, _ in env_steps}\n",
    "                    all_envs = set(range(20))  # assuming 20 environments\n",
    "                    failed_envs = all_envs - completed_envs\n",
    "                    if failed_envs:\n",
    "                        max_steps = result.get('max_steps_allowed', 300)\n",
    "                        print(f\"    Failed environments ({len(failed_envs)}/20): {sorted(failed_envs)}\")\n",
    "                        print(f\"    (Failed environments assigned {max_steps} steps)\")\n",
    "                else:\n",
    "                    print(f\"    No per-environment data available\")\n",
    "                    if 'mean_completion_steps' in result:\n",
    "                        print(f\"    Overall mean: {result['mean_completion_steps']:.1f} steps\")\n",
    "                \n",
    "                print()\n",
    "        else:\n",
    "            print(f\"  No raw data available for {method}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ca0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ff5315",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- If the notebook cannot find experiment folders, set the variables `franka_dir` and `robot_dir` manually to the correct experiment output directories and re-run the plotting cells.\n",
    "- Figures are saved with names prefixed by `paper_` in each experiment directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion-forcing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
